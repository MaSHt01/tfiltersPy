<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Understanding the Kalman Filter &mdash; tfilterspy 1.0.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="API Reference" href="api_cheatsheet.html" />
    <link rel="prev" title="Real World Usecases üé¢" href="examples.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            tfilterspy
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Real World Usecases üé¢</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Understanding the Kalman Filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="#understanding-particle-filters">Understanding  Particle Filters</a></li>
<li class="toctree-l1"><a class="reference internal" href="#parameter-estimation-methods">Parameter Estimation Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_cheatsheet.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="CONTRIBUTING.html">Contributing to TFiltersPy</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">tfilterspy</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Understanding the Kalman Filter</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/literature.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="understanding-the-kalman-filter">
<h1>Understanding the Kalman Filter<a class="headerlink" href="#understanding-the-kalman-filter" title="Permalink to this heading">ÔÉÅ</a></h1>
<p>Think of the Kalman Filter like a smart guesser ü§ñ.</p>
<p>At each step, it:
1. Predicts what will happen next.
2. Checks what <em>actually</em> happened (the measurement).
3. Adjusts its guess based on how wrong it was.</p>
<p>We do this using a bit of matrix magic ‚Äî here‚Äôs how it works:</p>
<p>Step 1: Predict (What do we <em>think</em> will happen?)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\hat{x}_{k|k-1} = F \cdot \hat{x}_{k-1|k-1}\\P_{k|k-1} = F \cdot P_{k-1|k-1} \cdot F^\top + Q\end{aligned}\end{align} \]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\hat{x}_{k|k-1}\)</span> is our predicted state at time <cite>k</cite>.</p></li>
<li><p><span class="math notranslate nohighlight">\(F\)</span> is the state transition matrix.</p></li>
<li><p><span class="math notranslate nohighlight">\(P_{k|k-1}\)</span> is the predicted uncertainty (covariance).</p></li>
<li><p><span class="math notranslate nohighlight">\(Q\)</span> is the process noise ‚Äî how much we think the system can change randomly.</p></li>
</ul>
<p>Step 2: Update (What did we <em>actually</em> see?)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}y_k = z_k - H \cdot \hat{x}_{k|k-1}\\S_k = H \cdot P_{k|k-1} \cdot H^\top + R\\K_k = P_{k|k-1} \cdot H^\top \cdot S_k^{-1}\end{aligned}\end{align} \]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(y_k\)</span> is the ‚Äúinnovation‚Äù ‚Äî the difference between what we saw (<cite>z_k</cite>) and what we predicted.</p></li>
<li><p><span class="math notranslate nohighlight">\(H\)</span> maps our state to what we <em>can</em> observe.</p></li>
<li><p><span class="math notranslate nohighlight">\(S_k\)</span> is the uncertainty in the measurement prediction.</p></li>
<li><p><span class="math notranslate nohighlight">\(R\)</span> is the observation noise ‚Äî how noisy our measurements are.</p></li>
<li><p><span class="math notranslate nohighlight">\(K_k\)</span> is the Kalman Gain ‚Äî it decides how much to trust the measurement vs the prediction.</p></li>
</ul>
<p>Step 3: Correct (Update our guess based on new info)</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\hat{x}_{k|k} = \hat{x}_{k|k-1} + K_k \cdot y_k\\P_{k|k} = (I - K_k \cdot H) \cdot P_{k|k-1}\end{aligned}\end{align} \]</div>
<ul class="simple">
<li><p>We update our estimate of the state and its uncertainty.</p></li>
</ul>
<p>Intuition:</p>
<ul class="simple">
<li><p>If the measurement is very noisy (big <span class="math notranslate nohighlight">\(R\)</span>), we trust our prediction more.</p></li>
<li><p>If the prediction is uncertain (big <span class="math notranslate nohighlight">\(P\)</span>), we trust the measurement more.</p></li>
</ul>
<p>This beautiful balance between <strong>what we expect</strong> and <strong>what we observe</strong> is what makes the Kalman Filter such a powerful tool for filtering out noise and estimating the hidden truth. ‚ú®</p>
</section>
<section id="understanding-particle-filters">
<h1>Understanding  Particle Filters<a class="headerlink" href="#understanding-particle-filters" title="Permalink to this heading">ÔÉÅ</a></h1>
<p>The Particle Filter is like a swarm of guesses (particles) trying to chase the truth. üêù
Each particle represents a hypothesis of where the system could be. As time moves on, we adjust how much we trust each guess based on what we observe.</p>
<p>Step 1: Initialization üê£</p>
<p>Start with <cite>N</cite> particles, each one initialized at the same known state (or sampled if you want variation):</p>
<div class="math notranslate nohighlight">
\[x_i^{(0)} = x_0, \quad w_i^{(0)} = \frac{1}{N}\]</div>
<p>Where:
- <span class="math notranslate nohighlight">\(x_i^{(0)}\)</span> is the initial state of the <em>i</em>-th particle
- <span class="math notranslate nohighlight">\(w_i^{(0)}\)</span> is its weight (uniform initially)</p>
<p>Step 2: Prediction üîÆ</p>
<p>Let each particle evolve through the state transition model and some random noise:</p>
<div class="math notranslate nohighlight">
\[x_i^{(k)} = f(x_i^{(k-1)}) + \epsilon_i^{(k)}\]</div>
<p>Where:
- <span class="math notranslate nohighlight">\(f(x)\)</span> is the state transition function
- <span class="math notranslate nohighlight">\(\epsilon_i^{(k)} \sim \mathcal{N}(0, Q)\)</span> is process noise</p>
<p>Step 3: Measurement Update üîç</p>
<p>Compare each particle‚Äôs prediction to the actual observation:</p>
<div class="math notranslate nohighlight">
\[w_i^{(k)} \propto w_i^{(k-1)} \cdot p(y^{(k)} \mid x_i^{(k)})\]</div>
<p>Typically, this likelihood is Gaussian:</p>
<div class="math notranslate nohighlight">
\[p(y^{(k)} \mid x_i^{(k)}) = \mathcal{N}(y^{(k)} \mid h(x_i^{(k)}), R)\]</div>
<p>Where:
- <span class="math notranslate nohighlight">\(h(x)\)</span> is the observation function
- <span class="math notranslate nohighlight">\(R\)</span> is the observation noise covariance</p>
<p>Normalize weights so they sum to 1:</p>
<div class="math notranslate nohighlight">
\[\sum_{i=1}^{N} w_i^{(k)} = 1\]</div>
<p>Step 4: Resampling ‚ôªÔ∏è</p>
<p>If most particles have near-zero weights, we resample to keep only good particles:</p>
<p>Draw <cite>N</cite> new particles <strong>with replacement</strong>, favoring high-weight ones.</p>
<div class="math notranslate nohighlight">
\[x_i^{(k)} \sim \{ x_j^{(k)} \}_{j=1}^{N}, \quad \text{with probability } w_j^{(k)}\]</div>
<p>Step 5: Estimate State üéØ</p>
<p>The best guess of the state is just a weighted average of all particles:</p>
<div class="math notranslate nohighlight">
\[\hat{x}^{(k)} = \sum_{i=1}^{N} w_i^{(k)} x_i^{(k)}\]</div>
<p>Bonus: Residuals</p>
<p>We can define the residual (aka innovation) at each step:</p>
<div class="math notranslate nohighlight">
\[r^{(k)} = y^{(k)} - \hat{y}^{(k)}, \quad \text{where } \hat{y}^{(k)} = h(\hat{x}^{(k)})\]</div>
<p>Use these for parameter estimation or diagnostics!</p>
<p>Intuition:</p>
<ul class="simple">
<li><p>If your model is spot-on, particles stay tight and track the truth.</p></li>
<li><p>If your model is wrong or noisy, particles spread out, but the filter still works by focusing on better guesses.</p></li>
</ul>
<p>That‚Äôs it ‚Äî just a clever crowd of guesses refining themselves with every new clue! üß†üé≤</p>
</section>
<section id="parameter-estimation-methods">
<h1>Parameter Estimation Methods<a class="headerlink" href="#parameter-estimation-methods" title="Permalink to this heading">ÔÉÅ</a></h1>
<p>When you‚Äôre not sure how much noise is in your system (Q and R), these methods help your filter figure it out.</p>
<p>Let‚Äôs break down each method simply:</p>
<p>Notation:
- <span class="math notranslate nohighlight">\(Q\)</span>: Process noise covariance (uncertainty in the system‚Äôs evolution).
- <span class="math notranslate nohighlight">\(R\)</span>: Observation noise covariance (uncertainty in what we observe).
- <span class="math notranslate nohighlight">\(y_t\)</span>: Observation at time t.
- <span class="math notranslate nohighlight">\(\hat{y}_t\)</span>: Predicted observation at time t from filter.
- <span class="math notranslate nohighlight">\(r_t = y_t - \hat{y}_t\)</span>: The <em>residual</em> or <em>innovation</em>.</p>
<ol class="arabic simple">
<li><p>Residual Analysis üìä</p></li>
</ol>
<p>This method says: ‚ÄúLet‚Äôs look at the errors and calculate how wild they are.‚Äù</p>
<p>We assume the residuals are due to noise. So we use their <strong>variance</strong> and <strong>covariance</strong> to estimate Q and R:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}R \approx \mathrm{Var}(r_t) = \frac{1}{T} \sum_{t=1}^{T} r_t r_t^\top\\Q \approx \mathrm{Cov}(r_t) = \frac{1}{T} \sum_{t=1}^{T} (r_t - \bar{r})(r_t - \bar{r})^\top\end{aligned}\end{align} \]</div>
<p>Where <span class="math notranslate nohighlight">\(\bar{r}\)</span> is the mean of the residuals.</p>
<ol class="arabic simple" start="2">
<li><p>Maximum Likelihood Estimation (MLE) üîç</p></li>
</ol>
<p>MLE says: ‚ÄúLet‚Äôs find the Q and R that <em>most likely</em> made our observations happen.‚Äù</p>
<p>We do it iteratively:
- Run the filter
- Get residuals
- Update Q and R to maximize the likelihood</p>
<p>Simplified:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Q^{(i+1)} = \mathrm{Var}(r_t^{(i)})\\R^{(i+1)} = \mathrm{Var}(r_t^{(i)})\end{aligned}\end{align} \]</div>
<p>Where <span class="math notranslate nohighlight">\(i\)</span> is the iteration index. We stop after a few rounds or when it converges.</p>
<ol class="arabic simple" start="3">
<li><p>Cross-Validation (CV) üîÅ</p></li>
</ol>
<p>Let‚Äôs split the data into parts (folds), train the filter on some, and validate on the rest.</p>
<p>For each fold:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\text{Train on } X_{\text{train}}, \quad \text{Validate on } X_{\text{val}}\\Q_{\text{fold}} = \mathrm{Cov}(r_t^{\text{train}}), \quad
R_{\text{fold}} = \mathrm{Var}(r_t^{\text{train}})\end{aligned}\end{align} \]</div>
<p>Then we compute the <strong>validation score</strong>:</p>
<div class="math notranslate nohighlight">
\[\text{Score}_{\text{fold}} = \frac{1}{N} \sum_{t \in \text{val}} \left\| y_t - \hat{y}_t \right\|^2\]</div>
<p>We pick the Q and R from the fold with the <strong>lowest score</strong>.</p>
<ol class="arabic simple" start="4">
<li><p>Adaptive Filtering (Online Updating) üîÑ</p></li>
</ol>
<p>This method says: ‚ÄúLet‚Äôs keep updating Q and R as we go using a small learning rate.‚Äù</p>
<p>Every new innovation <span class="math notranslate nohighlight">\(r_t\)</span> gives us new evidence to tweak Q and R:</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}Q_t = (1 - \alpha) Q_{t-1} + \alpha (r_t r_t^\top)\\R_t = (1 - \alpha) R_{t-1} + \alpha \cdot \mathrm{diag}(r_t r_t^\top)\end{aligned}\end{align} \]</div>
<p>Where:
- <span class="math notranslate nohighlight">\(\alpha\)</span> is the learning rate (e.g. 0.01)
- <span class="math notranslate nohighlight">\(r_t\)</span> is the innovation (residual)</p>
<p>The filter gets smarter over time, adjusting itself like a thermostat reacting to room temperature. üå°Ô∏è</p>
<p>These techniques are all about helping the filter ‚Äúlearn‚Äù how noisy the world is ‚Äî so it can be confident when it needs to be, and skeptical when things look fishy. üê†</p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="examples.html" class="btn btn-neutral float-left" title="Real World Usecases üé¢" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="api_cheatsheet.html" class="btn btn-neutral float-right" title="API Reference" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Thabang Mashinin-Sekhoto, Lebogang Mashinini-Sekhoto, Palesa Mashinini-Sekhoto.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>